{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e580a89f",
   "metadata": {},
   "source": [
    "# Проект"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ec28f",
   "metadata": {},
   "source": [
    "## Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a150a",
   "metadata": {},
   "source": [
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "\n",
    "В нашем распоряжении есть данные о поведении клиентов (файл _users_behavior.csv_), которые уже перешли на эти тарифы. Нужно сформировать выборки для обучения, для валидации и для тестов, затем построить модель для задачи классификации на выборке для обучения, которая выберет подходящий тариф. С помощью выборки для валидации нужно отобрать самые удачные модели и прогнать через них тестовые данные. Для каждой из выбранных моделей нужно посчитать точность (accuracy) на выборках для валидации и для тестов и на основании результатов выбрать наилучшую модель. Наилучшая модель должна иметь значение точности (accuracy) на валидационной и тестовой выборках не меньше, чем 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecdae2f",
   "metadata": {},
   "source": [
    "## Изучение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0290f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from  sklearn import model_selection\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "is_need_learn = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea8816",
   "metadata": {},
   "source": [
    "Откроем файл с данными и изучим его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931c810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filename, indexcol=None):\n",
    "    path_home = './datasets/' + filename\n",
    "    path_server = '/datasets/' + filename\n",
    "    if os.path.exists(path_home):\n",
    "        return pd.read_csv(path_home, index_col=indexcol)\n",
    "    elif os.path.exists(path_server):\n",
    "        return pd.read_csv(path_server, index_col=indexcol)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"cannot find file \" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942275d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open_file('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec6c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f56aa",
   "metadata": {},
   "source": [
    "В таблице 3214 строк и пять столбцов - _calls_, _minutes_, _messages_, _mb_used_ и _is_ultra_. Первые четыре столбца будут признаками, последний - целевым признаком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855556bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля клиентов, перешедших на тариф ultra: 0.30647168637212197\n",
      "Доля клиентов, перешедших на тариф ultra: 0.693528313627878\n"
     ]
    }
   ],
   "source": [
    "print('Доля клиентов, перешедших на тариф ultra:', data[data['is_ultra'] == 1]['is_ultra'].count()/data['is_ultra'].count())\n",
    "print('Доля клиентов, перешедших на тариф ultra:', data[data['is_ultra'] == 0]['is_ultra'].count()/data['is_ultra'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25da3e2c",
   "metadata": {},
   "source": [
    "Соотношение признаков примерно 3 к 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24676993",
   "metadata": {},
   "source": [
    "## Разбиение данных на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3077e5",
   "metadata": {},
   "source": [
    "Разделим данные на три выборки (обучающую, валидационную и тестовую). Деление будем производить в соотношении 3:1:1. Проверку модели мы будем проводить кросс-валидацией. Для кросс-валидации будем использовать класс StratifiedShuffleSplit библиотеки sci-kit learn, который самостоятельно делит поданную на вход выборку на обучающую и валидационную, поэтому руками нам нужно поделить нашу исходную выборку только на две части - в соотношении 4 к 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3fba5",
   "metadata": {},
   "source": [
    "В качестве признаков будем использовать всевозможные комбинации всех размеров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ae5e6",
   "metadata": {},
   "source": [
    "Сперва создадим выборки, затем определим набор всевозможных комбинаций столбцов. Выборки будем создавать отдельно для данных с положительным и отрицательным значениями целевого признака, чтобы соотношение классов на обучающих и тестовых данных было одинаковым и соответствовало соотношению в исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def10fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample size 2571\n",
      "Test sample size 643\n"
     ]
    }
   ],
   "source": [
    "features_1 = data[data['is_ultra'] == 1].loc[:, data.columns != 'is_ultra']\n",
    "target_1 = data[data['is_ultra'] == 1]['is_ultra']\n",
    "features_0 = data[data['is_ultra'] == 0].loc[:, data.columns != 'is_ultra']\n",
    "target_0 = data[data['is_ultra'] == 0]['is_ultra']\n",
    "\n",
    "train_features_1, test_features_1, train_target_1, test_target_1 = train_test_split(features_1, target_1, test_size=0.2, random_state=12345)\n",
    "train_features_0, test_features_0, train_target_0, test_target_0 = train_test_split(features_0, target_0, test_size=0.2, random_state=12345)\n",
    "\n",
    "train_features = pd.concat([train_features_1, train_features_0])\n",
    "test_features = pd.concat([test_features_1, test_features_0])\n",
    "train_target = pd.concat([train_target_1, train_target_0])\n",
    "test_target = pd.concat([test_target_1, test_target_0])\n",
    "\n",
    "print('Train sample size', train_features.shape[0])\n",
    "print('Test sample size', test_features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b313fdc",
   "metadata": {},
   "source": [
    "Теперь определим список всевозможных комбинаций признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42000554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['calls'],\n",
       " ['minutes'],\n",
       " ['messages'],\n",
       " ['mb_used'],\n",
       " ['calls', 'minutes'],\n",
       " ['calls', 'messages'],\n",
       " ['calls', 'mb_used'],\n",
       " ['minutes', 'messages'],\n",
       " ['minutes', 'mb_used'],\n",
       " ['messages', 'mb_used'],\n",
       " ['calls', 'minutes', 'messages'],\n",
       " ['calls', 'minutes', 'mb_used'],\n",
       " ['calls', 'messages', 'mb_used'],\n",
       " ['minutes', 'messages', 'mb_used'],\n",
       " ['calls', 'minutes', 'messages', 'mb_used']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "    comb = list(combinations(train_features.columns, i))\n",
    "    for a in comb:\n",
    "        features_list.append(list(a))\n",
    "    \n",
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bed634",
   "metadata": {},
   "source": [
    "В дальнейшем мы сможем обучать модели на отдельных признаках, просто итерируясь по этому списку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd624a",
   "metadata": {},
   "source": [
    "## Обучение и исследование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35292570",
   "metadata": {},
   "source": [
    "Мы будем использовать три алгоритма классификации в чистом виде с различными гиперпараметрами: решающее дерево, случайный лес и логистическую регрессию. Для каждого алгоритма обучим несколько моделей с разными гиперпараметрами, использующих различные комбинации признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc70fd4",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498400b",
   "metadata": {},
   "source": [
    "Мы будем использовать DecisionTreeClassifier из библиотеки sklearn. Гиперпараметры будем изменять следующим образом:\n",
    "\n",
    "* _criterion_: 'gini', 'entropy'\n",
    "\n",
    "Исходя из литературы, оба критерия разбиения узла на поддеревья примерно одинаковы (за исключением того, что индекс Джини в теории должен быть чуть быстрее из-за отсутствия необходимости считать логарифмы).\n",
    "\n",
    "* _max_features_ \n",
    "\n",
    "Максимальное количество признаков, которые следует учитывать при поиске лучшего разделения. Считается одним из важных гиперпараметров при настройке модели. Мы будем использовать все значения от 1 до общего количества признаков (набор признаков, как говорилось выше, мы тоже будем варьировать)\n",
    "\n",
    "* _max_depth_\n",
    "\n",
    "Максимальная глубина дерева. Важный гиперпараметр, предотвращающий переобучение. Мы будем использовать значения от 1 до 9 (учитывая, что у нас максимум четыре признака, вряд ли нам понадобится больше).\n",
    "\n",
    "* _min_samples_split_, _min_samples_leaf_\n",
    "\n",
    "Два важных и довольно зависимых друг от друга гиперпараметра. Первый определяет минимальное число элементов выборки в вершине, чтобы ее нужно было делить дальше на поддеревья, второй определяет минимальное число элементов выборки в листьях. Согласно статье https://arxiv.org/abs/1812.02207 оптимальные диапазоны для этих гиперпараметров при алгоритме построения дерева CART (который используется в sklearn) - (2,40) и (1, 20). Но из-за временных затрат мы проверим модели в диапазонах (2, 8) и (1, 8) соответственно.\n",
    "\n",
    "Параметры будем перебирать с помощью grid search, который удобно ищет наилучшую модель по нужному гиперпараметру и делает все за нас, включая кросс-валидацию.\n",
    "\n",
    "Дабы избавить ревьюера от необходимости ждать несколько часов в ожидании обучения моделей, я записал гиперпараметры наилучших моделей для каждого признака руками. Но если мсье/мадам знает толк в извращениях, то можно выставить флаг is_need_learn в значение True в любом месте отчета отсюда и раньше - тогда будет проведен поиск наилучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70ba143",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_class = []\n",
    "dec_tree_feat = []\n",
    "\n",
    "if is_need_learn == True:\n",
    "    dec_tree_class = []\n",
    "    dec_tree_feat = []\n",
    "    for feat in features_list:\n",
    "        parameters_dec_tree = {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_features' : range(1, len(feat) + 1),\n",
    "            'max_depth' : np.arange(1,10),\n",
    "            'min_samples_split' : range(2,8),\n",
    "            'min_samples_leaf' : range(1,8),\n",
    "        }\n",
    "        classifier = DecisionTreeClassifier(random_state = 12345)\n",
    "\n",
    "        cv = model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state = 12345)\n",
    "        dec_tree_cv = model_selection.GridSearchCV(classifier, parameters_dec_tree, scoring='accuracy', cv=cv)\n",
    "        %time dec_tree_cv.fit(train_features[feat], train_target)\n",
    "        dec_tree_class.append(dec_tree_cv)\n",
    "        dec_tree_feat.append(feat)\n",
    "else:\n",
    "    cv = model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state = 12345)\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(max_depth=3, max_features=1, min_samples_leaf=3,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls']], train_target))\n",
    "    dec_tree_feat.append(['calls'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=1,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['minutes']], train_target))\n",
    "    dec_tree_feat.append(['minutes'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=1, max_features=1,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['messages']], train_target))\n",
    "    dec_tree_feat.append(['messages'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(max_depth=1, max_features=1, \n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['mb_used']], train_target))\n",
    "    dec_tree_feat.append(['mb_used'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=1,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'minutes']], train_target))\n",
    "    dec_tree_feat.append(['calls', 'minutes'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=2,\n",
    "                       min_samples_leaf=5, random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'messages']], train_target))\n",
    "    dec_tree_feat.append(['calls', 'messages'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(max_depth=7, max_features=2, min_samples_leaf=5,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'mb_used']], train_target))\n",
    "    dec_tree_feat.append(['calls', 'mb_used'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=6, max_features=2,\n",
    "                       min_samples_leaf=7, random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['minutes', 'messages']], train_target))\n",
    "    dec_tree_feat.append(['minutes', 'messages'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(max_depth=5, max_features=2, min_samples_leaf=7,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['minutes', 'mb_used']], train_target))\n",
    "    dec_tree_feat.append(['minutes', 'mb_used'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=1,\n",
    "                       min_samples_leaf=7, random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['messages', 'mb_used']], train_target))\n",
    "    dec_tree_feat.append(['messages', 'mb_used'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(max_depth=3, max_features=1, min_samples_leaf=5,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'minutes', 'messages']], train_target))\n",
    "    dec_tree_feat.append(['calls', 'minutes', 'messages'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(max_depth=5, max_features=3, min_samples_leaf=7,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'minutes', 'mb_used']], train_target))\n",
    "    dec_tree_feat.append(['calls', 'minutes', 'mb_used'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(max_depth=5, max_features=2, min_samples_leaf=7,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'messages', 'mb_used']], train_target))\n",
    "    dec_tree_feat.append(['calls', 'messages', 'mb_used'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=3,\n",
    "                       min_samples_leaf=6, random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['minutes', 'messages', 'mb_used']], train_target))\n",
    "    dec_tree_feat.append(['minutes', 'messages', 'mb_used'])\n",
    "    \n",
    "    dec_tree_class.append(model_selection.GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=6, max_features=2,\n",
    "                       min_samples_leaf=5, random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'minutes', 'messages', 'mb_used']], train_target))\n",
    "    dec_tree_feat.append(['calls', 'minutes', 'messages', 'mb_used'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f0cc37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7648522550544323\n",
      "{}\n",
      "['calls']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
      "                       max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7620528771384136\n",
      "{}\n",
      "['minutes']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=1,\n",
      "                       max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.72099533437014\n",
      "{}\n",
      "['messages']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7567651632970451\n",
      "{}\n",
      "['mb_used']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
      "                       max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7623639191290824\n",
      "{}\n",
      "['calls', 'minutes']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
      "                       max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7744945567651633\n",
      "{}\n",
      "['calls', 'messages']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "                       max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7981337480559876\n",
      "{}\n",
      "['calls', 'mb_used']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=7, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7735614307931571\n",
      "{}\n",
      "['minutes', 'messages']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=7, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.8003110419906687\n",
      "{}\n",
      "['minutes', 'mb_used']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
      "                       max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=7, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7695178849144635\n",
      "{}\n",
      "['messages', 'mb_used']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.7738724727838259\n",
      "{}\n",
      "['calls', 'minutes', 'messages']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=3, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=7, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.8018662519440124\n",
      "{}\n",
      "['calls', 'minutes', 'mb_used']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=7, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.8049766718506999\n",
      "{}\n",
      "['calls', 'messages', 'mb_used']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
      "                       max_features=3, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=6, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.8021772939346812\n",
      "{}\n",
      "['minutes', 'messages', 'mb_used']\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.8018662519440124\n",
      "{}\n",
      "['calls', 'minutes', 'messages', 'mb_used']\n",
      "\n",
      "Best model\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=7, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=12345, splitter='best')\n",
      "0.8049766718506999\n",
      "{}\n",
      "['calls', 'messages', 'mb_used']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_accuracy = 0\n",
    "max_tree_ind = 0\n",
    "for i in range(len(dec_tree_class)):\n",
    "    print(dec_tree_class[i].best_estimator_) \n",
    "    print(dec_tree_class[i].best_score_)\n",
    "    print(dec_tree_class[i].best_params_)\n",
    "    print(dec_tree_feat[i])\n",
    "    print()\n",
    "    if dec_tree_class[i].best_score_ > max_accuracy:\n",
    "        max_accuracy = dec_tree_class[i].best_score_\n",
    "        max_tree_ind = i\n",
    "\n",
    "print('Best model')\n",
    "print(dec_tree_class[max_tree_ind].best_estimator_) \n",
    "print(dec_tree_class[max_tree_ind].best_score_)\n",
    "print(dec_tree_class[max_tree_ind].best_params_)\n",
    "print(dec_tree_feat[max_tree_ind])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1016a246",
   "metadata": {},
   "source": [
    "Как видно, уже на 2 признаках точность обученной модели на тестовых данных превышает 0.8, а для 3 и больше признаков она больше 0.8 для любых наборов признаков. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a7588",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fb3d0",
   "metadata": {},
   "source": [
    "Будем использовать класс RandomForestClassifier из библиотеки sklearn. Этот класс имеет схожие гиперпараметры с классом DecisionTreeClassifier, которые касаются построения отдельных деревьев, а также гиперпараметры, отвечающие за алгоритм как ансамбль алгоритмов (количество деревьев _n_estimators_, использование _bootstrap_ для создания подвыборок для обучения поддеревьев и т.д.). Так как RandomForestClassifier обучается значительно дольше и имеет больше гиперпараметров, часть гиперпараметров, которые мы использовали в DecisionTreeClassifier, придется в этом пункте урезать. В итоге получаются следующие диапазоны:\n",
    "\n",
    "* _n_estimators_ : от 1 до 100 с шагом 10\n",
    "* _max_features_ : от 1 до n, где n - общее количество признаков\n",
    "* _max_depth_ : от 1 до 80 с шагом 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a959d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_class = []\n",
    "random_forest_feat = []\n",
    "if is_need_learn == True:\n",
    "    for feat in features_list:\n",
    "        parameters_random_forest = {\n",
    "            'n_estimators' : range(1, 100, 10),\n",
    "            'max_features' : range(1, len(feat) + 1),\n",
    "            'criterion': ['gini'],\n",
    "            'max_depth' : range(1, 80, 5),\n",
    "        }\n",
    "        classifier = RandomForestClassifier(random_state = 12345)\n",
    "\n",
    "        cv = model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state = 12345)\n",
    "        random_forest_cv = model_selection.GridSearchCV(classifier, parameters_random_forest, scoring='accuracy', cv=cv)\n",
    "        %time random_forest_cv.fit(train_features[feat], train_target)\n",
    "        random_forest_class.append(random_forest_cv)\n",
    "        random_forest_feat.append(feat)\n",
    "else:\n",
    "    cv = model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state = 12345)\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=1, n_estimators=33,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls']], train_target))\n",
    "    random_forest_feat.append(['calls'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=1, n_estimators=33,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['minutes']], train_target))\n",
    "    random_forest_feat.append(['minutes'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=1, max_features=1, n_estimators=1,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['messages']], train_target))\n",
    "    random_forest_feat.append(['messages'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=1, max_features=1, n_estimators=33,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['mb_used']], train_target))\n",
    "    random_forest_feat.append(['mb_used'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=1, n_estimators=97,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'minutes']], train_target))\n",
    "    random_forest_feat.append(['calls', 'minutes'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=1, n_estimators=73,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'messages']], train_target))\n",
    "    random_forest_feat.append(['calls', 'messages'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=1, n_estimators=41,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'mb_used']], train_target))\n",
    "    random_forest_feat.append(['calls', 'mb_used'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=1, n_estimators=89,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['minutes', 'messages']], train_target))\n",
    "    random_forest_feat.append(['minutes', 'messages'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=2, n_estimators=9,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['minutes', 'mb_used']], train_target))\n",
    "    random_forest_feat.append(['minutes', 'mb_used'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=2, n_estimators=25,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['messages', 'mb_used']], train_target))\n",
    "    random_forest_feat.append(['messages', 'mb_used'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=1, n_estimators=25,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'minutes', 'messages']], train_target))\n",
    "    random_forest_feat.append(['calls', 'minutes', 'messages'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=6, max_features=3, n_estimators=65,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'minutes', 'mb_used']], train_target))\n",
    "    random_forest_feat.append(['calls', 'minutes', 'mb_used'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=11, max_features=1, n_estimators=97,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'messages', 'mb_used']], train_target))\n",
    "    random_forest_feat.append(['calls', 'messages', 'mb_used'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=11, max_features=1, n_estimators=57,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['minutes', 'messages', 'mb_used']], train_target))\n",
    "    random_forest_feat.append(['minutes', 'messages', 'mb_used'])\n",
    "    \n",
    "    random_forest_class.append(model_selection.GridSearchCV(RandomForestClassifier(max_depth=11, max_features=2, n_estimators=97,\n",
    "                       random_state=12345), {}, scoring='accuracy', cv=cv).fit(train_features[['calls', 'minutes', 'messages', 'mb_used']], train_target))\n",
    "    random_forest_feat.append(['calls', 'minutes', 'messages', 'mb_used'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64aec0f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=33,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7601866251944013\n",
      "{}\n",
      "['calls']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=33,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7598755832037325\n",
      "{}\n",
      "['minutes']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=1, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7219284603421462\n",
      "{}\n",
      "['messages']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=1, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=33,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7567651632970451\n",
      "{}\n",
      "['mb_used']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=97,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7601866251944013\n",
      "{}\n",
      "['calls', 'minutes']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=73,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7769828926905132\n",
      "{}\n",
      "['calls', 'messages']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=41,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.8043545878693623\n",
      "{}\n",
      "['calls', 'mb_used']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=89,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7772939346811819\n",
      "{}\n",
      "['minutes', 'messages']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=9,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.8062208398133748\n",
      "{}\n",
      "['minutes', 'mb_used']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7754276827371696\n",
      "{}\n",
      "['messages', 'mb_used']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=25,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.7794712286158632\n",
      "{}\n",
      "['calls', 'minutes', 'messages']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=3, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=65,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.8065318818040436\n",
      "{}\n",
      "['calls', 'minutes', 'mb_used']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=11, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=97,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.8118195956454122\n",
      "{}\n",
      "['calls', 'messages', 'mb_used']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=11, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=57,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.808398133748056\n",
      "{}\n",
      "['minutes', 'messages', 'mb_used']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=11, max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=97,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.8139968895800933\n",
      "{}\n",
      "['calls', 'minutes', 'messages', 'mb_used']\n",
      "\n",
      "Best model\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=11, max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=97,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.8139968895800933\n",
      "{}\n",
      "['calls', 'minutes', 'messages', 'mb_used']\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = 0\n",
    "max_forest_ind = 0\n",
    "for i in range(len(random_forest_class)):\n",
    "    print(random_forest_class[i].best_estimator_) \n",
    "    print(random_forest_class[i].best_score_)\n",
    "    print(random_forest_class[i].best_params_)\n",
    "    print(dec_tree_feat[i])\n",
    "    print()\n",
    "    if random_forest_class[i].best_score_ > max_accuracy:\n",
    "        max_accuracy = random_forest_class[i].best_score_\n",
    "        max_forest_ind = i\n",
    "        \n",
    "print('Best model')\n",
    "print(random_forest_class[max_forest_ind].best_estimator_) \n",
    "print(random_forest_class[max_forest_ind].best_score_)\n",
    "print(random_forest_class[max_forest_ind].best_params_)\n",
    "print(dec_tree_feat[max_forest_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc85d0b",
   "metadata": {},
   "source": [
    "Значения, как и следовало ожидать, имеют похожие свойства на те, что у решающего дерева, только точность несколько выше. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886e8a0",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d4a77",
   "metadata": {},
   "source": [
    "Будем использовать LogisticRegressionCV (говорят, он позволяет проще перебирать один из гиперпараметров). Диапазоны гиперпараметров следующие:\n",
    "* _solver_\n",
    "\n",
    "Алгоритм, использующийся для решения задачи оптимизации. В нашем отчете будут использоваться алгоритмы 'lbfgs', 'sag', 'saga'. Почему только они? Потому что только с ними не вылетало ошибки о несходимости алгоритма с ЛЮБЫМ числом шагов итерации:)\n",
    "\n",
    "* _max_iter_ \n",
    "\n",
    "Число итераций алгоритма, после которого в случае, если алгоритму сойтись не удалось, его работа прекращается. Чем он больше, тем лучше должно быть алгоритму, но все зависит от данных. Я выбрал значение 10000, потому что где-то увидел это значение как пример.\n",
    "\n",
    "* _С_\n",
    "\n",
    "Параметр регуляризации. Одна из величин, фигурирующая в задаче оптимизации. Чем она больше, тем более сложные зависимости способна вычленить модель, однако слишком большое значение этого параметра может привести к переобучению. Мы будем использовать 200 значений в диапазоне от 0.01 до 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3793d727",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlin_reg_class = []\\nlin_reg_feat = []\\nfor feat in features_list:\\n    parameters_log_reg = {\\n        'solver' : ['lbfgs', 'sag', 'saga'],\\n        'max_iter' : [10000]\\n    }\\n    c_values = np.logspace(-2, 3, 200)\\n\\n    cv = model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state = 12345)\\n    classifier = LogisticRegressionCV(Cs=c_values, cv=cv, random_state = 12345)\\n    log_reg_cv = model_selection.GridSearchCV(classifier, parameters_log_reg, scoring='accuracy', cv=cv)\\n    log_reg_cv.fit(train_features[feat], train_target)\\n    lin_reg_class.append(log_reg_cv)\\n    lin_reg_feat.append(feat)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lin_reg_class = []\n",
    "lin_reg_feat = []\n",
    "for feat in features_list:\n",
    "    parameters_log_reg = {\n",
    "        'solver' : ['lbfgs', 'sag', 'saga'],\n",
    "        'max_iter' : [10000]\n",
    "    }\n",
    "    c_values = np.logspace(-2, 3, 200)\n",
    "\n",
    "    cv = model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state = 12345)\n",
    "    classifier = LogisticRegressionCV(Cs=c_values, cv=cv, random_state = 12345)\n",
    "    log_reg_cv = model_selection.GridSearchCV(classifier, parameters_log_reg, scoring='accuracy', cv=cv)\n",
    "    log_reg_cv.fit(train_features[feat], train_target)\n",
    "    lin_reg_class.append(log_reg_cv)\n",
    "    lin_reg_feat.append(feat)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d7be7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmax_accuracy = 0\\nmax_log_ind = 0\\nfor i in range(len(lin_reg_class)):\\n    print(lin_reg_class[i].best_estimator_) \\n    print(lin_reg_class[i].best_score_)\\n    print(lin_reg_class[i].best_params_)\\n    print(dec_tree_feat[i])\\n    print()\\n    if lin_reg_class[i].best_score_ > max_accuracy:\\n        max_accuracy = lin_reg_class[i].best_score_\\n        max_log_ind = i\\n        \\nprint('Best model')\\nprint(lin_reg_class[max_log_ind].best_estimator_) \\nprint(lin_reg_class[max_log_ind].best_score_)\\nprint(lin_reg_class[max_log_ind].best_params_)\\nprint(dec_tree_feat[max_log_ind])\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "max_accuracy = 0\n",
    "max_log_ind = 0\n",
    "for i in range(len(lin_reg_class)):\n",
    "    print(lin_reg_class[i].best_estimator_) \n",
    "    print(lin_reg_class[i].best_score_)\n",
    "    print(lin_reg_class[i].best_params_)\n",
    "    print(dec_tree_feat[i])\n",
    "    print()\n",
    "    if lin_reg_class[i].best_score_ > max_accuracy:\n",
    "        max_accuracy = lin_reg_class[i].best_score_\n",
    "        max_log_ind = i\n",
    "        \n",
    "print('Best model')\n",
    "print(lin_reg_class[max_log_ind].best_estimator_) \n",
    "print(lin_reg_class[max_log_ind].best_score_)\n",
    "print(lin_reg_class[max_log_ind].best_params_)\n",
    "print(dec_tree_feat[max_log_ind])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a50ad",
   "metadata": {},
   "source": [
    "Модели обучились быстрее, чем с предыдущими алгоритмами, однако имеют более низкие значения accuracy - лучшая модель даже ниже нашего порога в 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07e3f6",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61281d9b",
   "metadata": {},
   "source": [
    "Наилучшие результаты (0.8 и больше) показали модели, обученные алгоритмами решающего дерева и случайного леса (имплементации sklearn). Хорошие результаты были показаны как на всех четырех признаках, так и на комбинациях с меньшим числом (2 и 3 признака). Логистическая регрессия показала наихудшие результаты и в дальшейшем тестировании принимать участие не будет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e28d4",
   "metadata": {},
   "source": [
    "## Тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05933870",
   "metadata": {},
   "source": [
    "Мы обучим две модели - наилучшую с использованием алгоритма решающего дерева и наилучшую с использованием алгоритма случайного леса. Обучать модели будем на объединенных выборках для тестов и для валидации (больше информации при обучении - лучше модель) и посмотрим на результаты работы этих моделей на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d3505",
   "metadata": {},
   "source": [
    "Для алгоритма случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d95bae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853810264385692"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model = RandomForestClassifier(**random_forest_class[max_forest_ind].best_params_)\n",
    "first_model.fit(train_features[random_forest_feat[max_forest_ind]], train_target)\n",
    "test_predictions = first_model.predict(test_features[random_forest_feat[max_forest_ind]])\n",
    "accuracy_score(test_target, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4627cc",
   "metadata": {},
   "source": [
    "Для алгоритма дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d3b51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7200622083981337"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model = DecisionTreeClassifier(**dec_tree_class[max_tree_ind].best_params_)\n",
    "first_model.fit(train_features[dec_tree_feat[max_tree_ind]], train_target)\n",
    "test_predictions = first_model.predict(test_features[dec_tree_feat[max_tree_ind]])\n",
    "accuracy_score(test_target, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e20b59",
   "metadata": {},
   "source": [
    "Как видим, модель на алгоритме дерева решений показала неприемлемый результат, в то время как модель на алгоритме случайного леса лишь немного ухудшила показатель точности по сравнению с тестовой выборкой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aaa648",
   "metadata": {},
   "source": [
    "Проверим также нашу модель на \"адекватность\", сравнив ее точность с простыми классификаторами. Первый простой классификатор будет выдавать константный ответ, равный самому популярному ответу в обучающей выборке, а второй - выдавать ответы согласно распределению такому же, какое было среди элементов обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03fb4eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6127527216174183\n",
      "0.6936236391912908\n"
     ]
    }
   ],
   "source": [
    "dummy_model_1 = DummyClassifier(random_state=12345, strategy='stratified').fit(train_features[random_forest_feat[max_forest_ind]], train_target)\n",
    "test_predictions = dummy_model_1.predict(test_features[random_forest_feat[max_forest_ind]])\n",
    "print(accuracy_score(test_target, test_predictions))\n",
    "\n",
    "dummy_model_2 = DummyClassifier(random_state=12345, strategy='most_frequent').fit(train_features[random_forest_feat[max_forest_ind]], train_target)\n",
    "test_predictions = dummy_model_2.predict(test_features[random_forest_feat[max_forest_ind]])\n",
    "print(accuracy_score(test_target, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6434c9f",
   "metadata": {},
   "source": [
    "Как видимо, модель случайного леса значительно лучше подобных моделей, что говорит о ее адекватности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9dac95",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f94bd9",
   "metadata": {},
   "source": [
    "Первое, что хотелось бы написать в выводе (на самом деле это надо в конец, но не все ревьюеры читают вывод до конца:)) - далеко не факт, что я бы использовал в этой задаче машинное обучение. Самым логичным вариантом лично для меня выглядит подсчет предполагаемых трат клиентов, как если бы они пользовались услугами так, как указано в их данных за предыдущие месяцы, но при этом они были бы пользователями тарифа Смарт или Ультра. При каком тарифе траты минимальны - тот тариф и можно было бы предложить конкретному клиенту на замену архивного тарифа. Не исключено, что этот способ мог показать не самые лучшие результаты, но он считается безо всяких машинных обучений всего в несколько строк кода и имеет под собой хорошее логическое объяснение.\n",
    "\n",
    "Но раз стояла задача найти наилучшую модель среди тех, что худо-бедно изучил автор отчета - то она выполнена. Были изучены данные, определены признаки и целевой признак. Для целевого признака было вычислено соотношение классов. \n",
    "\n",
    "На основании изученного все данные были поделены на тестовую и обучающую выборки в соотношении 4 к 1 с сохранением соотношения классов в каждой из выборок. \n",
    "\n",
    "Были выбраны три алгоритма машинных обучения (решающее дерево, случайный лес, логистическая регрессия) и их реализации в библиотеке sci-kit learn. Для каждой реализации был подобран набор гиперпараметров. Для каждого набора гиперпараметров, а также для всех множеств наборов признаков были обучены на тестовой выборке модели. Проверка качества модели производилась кросс-валидацией с 5 делениями. Для каждого алгоритма была определена модель, показывающая лучшее значение точности (accuracy) на обучающей выборке, превышающая при этом заранее определенную границу 0.75. Таких модели оказалось две - одна, реализующая алгоритм решающего дерева (точность 0.8), вторая - реализующая алгоритм случайного леса (точность 0.81). Модели на основе алгоритма логистической регрессии границу в 0.75 не преодолели.\n",
    "\n",
    "Каждая из двух моделей была переобучена на всей обучающей выборке и проверена на тестовой выборке. Модель на основе алгоритма случайного леса показала незначительное изменение точности (0.79 по сравнению с 0.81 на обучающей выборке). Модель на основе алгоритма решающего дерева, напротив, показала серьезное ухудшение качества (0.73 по сравнению с 0.79). \n",
    "\n",
    "Как итог - была выбрана и обучена наилучшая модель с точностью свыше 0.75. Исходная задача полностью выполнена."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
